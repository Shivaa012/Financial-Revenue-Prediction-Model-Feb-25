# -*- coding: utf-8 -*-
"""company_revenue_prediction_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KJWdXWtKrfWcKkC4KqoGyeKaifXwtuCi
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Load Dataset
file_path = "/content/incomeStatementHistory_annually.csv"
df = pd.read_csv(file_path)

# Select Relevant Columns
features = [
    "grossProfit",
    "operatingIncome",
    "costOfRevenue",
    "totalOperatingExpenses",
    "netIncome",
    "incomeBeforeTax",
    "netIncomeFromContinuingOps",
    "interestExpense"
]
target = "totalRevenue"

# Drop rows with missing values in features OR target
df = df[features + [target]].dropna()

# Apply Log Transformation to Target Variable, handling potential errors
# Replace zero or negative values with a small positive value before log transformation
df[target] = np.log1p(df[target].where(df[target] > 0, 1e-10))

# Split Data
X = df[features]
y = df[target]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize Features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Train Linear Regression Model
lr = LinearRegression()
lr.fit(X_train_scaled, y_train)
y_pred_lr = lr.predict(X_test_scaled)

# Train Random Forest Model with Hyperparameter Tuning
rf = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)
rf.fit(X_train_scaled, y_train)
y_pred_rf = rf.predict(X_test_scaled)

# Reverse Log Transformation
y_pred_lr = np.expm1(y_pred_lr)
y_pred_rf = np.expm1(y_pred_rf)
y_test = np.expm1(y_test)

# Model Evaluation
def evaluate_model(y_true, y_pred, model_name):
    mae = mean_absolute_error(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    print(f"\nüìä {model_name} Performance:")
    print(f"MAE: {mae:.2f}")
    print(f"MSE: {mse:.2f}")
    print(f"R¬≤ Score: {r2:.4f}")

evaluate_model(y_test, y_pred_lr, "Linear Regression")
evaluate_model(y_test, y_pred_rf, "Random Forest")

# Feature Importance (Random Forest)
feature_importance = pd.Series(rf.feature_importances_, index=features).sort_values(ascending=False)
print("\nüîç Feature Importance (Random Forest):")
print(feature_importance)

# Plot Feature Importance
plt.figure(figsize=(8, 5))
sns.barplot(x=feature_importance, y=feature_importance.index)
plt.xlabel("Feature Importance Score")
plt.ylabel("Features")
plt.title("Feature Importance in Predicting Revenue")
plt.show()

# Predict Revenue for New Input
def predict_revenue(model, scaler):
    # Adjusted input values for better standardization and accuracy
    new_data_values = [262067000, 2084000, 665897000, 925880000, -53327000, -44025000, -53327000, -23076000]

    # Convert input into a DataFrame
    new_data = pd.DataFrame([new_data_values], columns=features)

    # Standardize the input data
    new_data_scaled = scaler.transform(new_data)

    # Predict revenue
    predicted_revenue = model.predict(new_data_scaled)[0]

    # Reverse Log Transformation
    predicted_revenue = np.expm1(predicted_revenue)

    print(f"\nüí∞ Predicted Revenue: ${predicted_revenue:,.2f}")

# Call function to predict revenue using Random Forest
predict_revenue(rf, scaler)